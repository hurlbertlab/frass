julianDayTime = function(date, hour_min) {
require(lubridate)
jday = yday(date)
temp = sapply(strsplit(hour_min, ":"), function(x) {
x = as.numeric(x)
x[1] + x[2]/60
})
output = jday + temp/24
return(output)
}
# Function for plotting frass phenology
#   minReliability is the minimum reliability score for including in the analysis.
#    3 - reliable, no obvious problems
#    2 - frass traps wet, or potential minor issues
#    1 - major problems, unreliable frass data
frassplot = function(frassdata, inputSite, year, color = 'black', new = T,
var = 'mass', minReliability = 0, xlab = 'Julian day', ylab = '', ...) {
temp = filter(frassdata, site == inputSite, Year == year, reliability >= minReliability) %>%
data.frame()
if (new) {
plot(temp$jday, temp[, var], xlab = xlab, ylab = ylab,
type = 'l', col = color, ...)
} else {
points(temp$jday, temp[, var], type = 'l', col = color, ...)
}
}
# Get frass data and then get julian days and times
data = frassData(open = T) %>%
filter(!is.na(Time.Set) & !is.na(Time.Collected)) %>%
mutate(Date.Set = as.Date(Date.Set, format = "%m/%d/%Y"),
Time.Set = as.character(Time.Set),
Time.Collected = as.character(Time.Collected),
Date.Collected = as.Date(Date.Collected, format = "%m/%d/%Y"),
Year = format(Date.Collected, "%Y"),
jday.Set = julianDayTime(Date.Set, Time.Set),
jday.Collected = julianDayTime(Date.Collected, Time.Collected),
frass.mg.d = Frass.mass..mg./(jday.Collected - jday.Set),
frass.no.d = Frass.number/(jday.Collected - jday.Set),
jday = (floor(jday.Collected) + floor(jday.Set))/2)
# Sampling event data that specify reliability of data on any given date
# (due to storms, etc that may affect frass recovery)
url = "https://docs.google.com/spreadsheets/d/1RwXzwhHUbP0m5gKSOVhnKZbS1C_NrbdfHLglIVCzyFc/edit#gid=1611171427"
events = gsheet2tbl(url)
events$date = as.Date(events$date, format = "%m/%d/%Y")
meanfrass = data %>%
filter(!is.na(Frass.mass..mg.)) %>%
mutate(site = ifelse(Site=="Botanical Garden", 8892356, 117)) %>%
group_by(site, Date.Collected, Year, jday) %>%
summarize(mass = mean(frass.mg.d, na.rm=T),
density = mean(frass.no.d, na.rm=T)) %>%
left_join(events[, c('date', 'site', 'reliability')], by = c('Date.Collected' = 'date',
'site' = 'site')) %>%
rename(date = Date.Collected)
write.csv(meanfrass, "data/arthropods/frass_by_day_2015-2017.csv", row.names = F)
# Prairie Ridge
frassplot(meanfrass, inputSite = 117, 2015, 'red', new = T, var = 'mass', xlim = c(138, 205),
ylim = c(0, 6), lwd = 2, minReliability = 1, lty = 'dotted', main = 'PR, 2015')
frassplot(meanfrass, inputSite = 117, 2015, 'red', new = F, var = 'mass',
lwd = 3, minReliability = 2, lty = 'dashed')
frassplot(meanfrass, inputSite = 117, 2015, 'red', new = F, var = 'mass',
lwd = 4, minReliability = 3, lty = 'solid')
par(new=T)
prlep15.mass = meanDensityByDay(beatvis.pr, ordersToInclude = "LEPL", inputYear = 2015,
inputSite = 117, jdRange = c(138,205), outlierCount = 30,
plot = T, plotVar = 'meanBiomass', xlim = c(138, 205),
lwd = 4, col = 'blueviolet', yaxt = 'n', ylab = '')
#plot compiling Prairie Ridge frass from 2015 through 2018. Not showing 2016 & 2017 data due to an error - needs trouble shooting.
frassplot(meanfrass, inputSite = 117, 2015, 'red', new = T, var = 'mass', xlim = c(138,205),
ylim = c(0, 11.5), lwd = 2, minReliability = 2, xlab = "Julian Day", ylab = "Frass (mg./day)", lty = 'solid', main = 'Prairie Ridge Frass')
frassplot(meanfrass, inputSite = 117, 2016, 'green', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 11.5), lwd = 2, minReliability = 2, lty = 'twodash', main = 'Prairie Ridge Frass')
frassplot(meanfrass, inputSite = 117, 2017, 'orange', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 11.5), lwd = 2, minReliability = 2, lty = 'dotted', main = 'Prairie Ridge Frass')
frassplot(meanfrass, inputSite = 117, 2018, 'blue', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 11.5), lwd = 2, minReliability = 2, lty = 'dashed', main = 'Prairie Ridge Frass')
#legend to decode graphic
legend(137, 11.6, title = "Survey Year", c("2015", "2016", "2017", "2018"), cex = .7, bty = "y", y.intersp = .8,
lty=c("solid", "twodash", "dotted", "dashed"), col=c("red", "green", "orange", "blue"))
frassplot(meanfrass, inputSite = 117, 2015, 'red', new = T, var = 'mass', xlim = c(138,205),
ylim = c(0, 11.5), lwd = 2, minReliability = 2, xlab = "Julian Day", ylab = "Frass (mg./day)", lty = 'solid', main = 'Prairie Ridge Frass')
frassplot(meanfrass, inputSite = 117, 2016, 'green', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 11.5), lwd = 2, minReliability = 2, lty = 'twodash', main = 'Prairie Ridge Frass')
frassplot(meanfrass, inputSite = 117, 2017, 'orange', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 11.5), lwd = 2, minReliability = 2, lty = 'dotted', main = 'Prairie Ridge Frass')
frassplot(meanfrass, inputSite = 117, 2018, 'blue', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 11.5), lwd = 2, minReliability = 2, lty = 'dashed', main = 'Prairie Ridge Frass')
#legend to decode graphic
legend(137, 11.6, title = "Survey Year", c("2015", "2016", "2017", "2018"), cex = .7, bty = "y", y.intersp = .8,
lty=c("solid", "twodash", "dotted", "dashed"), col=c("red", "green", "orange", "blue"))
frassplot(meanfrass, inputSite = 8892356, 2015, 'red', new = T, var = 'mass', xlim = c(138,205),
ylim = c(0, 10.14), lwd = 2, minReliability = 2, xlab = "Julian Day", ylab = "Frass (mg./day)", lty = 'solid', main = 'NCBG Frass')
frassplot(meanfrass, inputSite = 8892356, 2016, 'green', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 10.14), lwd = 2, minReliability = 2, lty = 'twodash', main = 'NCBG Frass')
frassplot(meanfrass, inputSite = 8892356, 2017, 'orange', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 10.14), lwd = 2, minReliability = 2, lty = 'dotted', main = 'NCBG Frass')
frassplot(meanfrass, inputSite = 8892356, 2018, 'blue', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 10.14), lwd = 2, minReliability = 2, lty = 'dashed', main = 'NCBG Frass')
#legend to decode graphic
legend(136, 10.2, title = "Survey Year", c("2015", "2016", "2017", "2018"), cex = .7, bty = "n", y.intersp = .8,
lty=c("solid", "twodash", "dotted", "dashed"), col=c("red", "green", "orange", "blue"), lwd = 2)
frassplot(meanfrass, inputSite = 8892356, 2015, 'red', new = T, var = 'mass', xlim = c(138,205),
ylim = c(0, 10.14), lwd = 2, minReliability = 3, xlab = "Julian Day", ylab = "Frass (mg./day)", lty = 'solid', main = 'NCBG Frass')
frassplot(meanfrass, inputSite = 8892356, 2016, 'green', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 10.14), lwd = 2, minReliability = 3, lty = 'twodash', main = 'NCBG Frass')
frassplot(meanfrass, inputSite = 8892356, 2017, 'orange', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 10.14), lwd = 2, minReliability = 3, lty = 'dotted', main = 'NCBG Frass')
frassplot(meanfrass, inputSite = 8892356, 2018, 'blue', new = F, var = 'mass', xlim = c(138,205),
ylim = c(0, 10.14), lwd = 2, minReliability = 3, lty = 'dashed', main = 'NCBG Frass')
#legend to decode graphic
legend(136, 10.2, title = "Survey Year", c("2015", "2016", "2017", "2018"), cex = .7, bty = "n", y.intersp = .8,
lty=c("solid", "twodash", "dotted", "dashed"), col=c("red", "green", "orange", "blue"), lwd = 2)
frassLoad = function(open = T, write = F) {
require(gsheet)
url = "https://docs.google.com/spreadsheets/d/1RwXzwhHUbP0m5gKSOVhnKZbS1C_NrbdfHLglIVCzyFc/edit#gid=806965256"
data = gsheet2tbl(url)
if (write) {
# Write a copy
write.csv(data, paste('data/frass_', Sys.Date(), '.csv', sep = ''),
row.names = F)
}
if (open) { return (data) }
}
# Script for analyzing filter paper data
library(gsheet)
library(dplyr)
library(tidyr)
# Function for reading in frass data from GoogleDoc
# *if aim is to backup GoogleDoc and write to disk only, then open =F and write = T
# *if aim is to use data without writing to disk, then open = T and write = F
frassData = function(open = F, write = F) {
require(gsheet)
url = "https://docs.google.com/spreadsheets/d/1RwXzwhHUbP0m5gKSOVhnKZbS1C_NrbdfHLglIVCzyFc/edit#gid=1479231778"
data = gsheet2tbl(url)
if (write) {
# Write a copy
write.csv(data, paste('data/frass_', Sys.Date(), '.csv', sep = ''),
row.names = F)
}
if (open) { return (data) }
}
# Function that takes a date field (formatted as %m/%d/%Y) and a time field
# (hh:mm in 24h time), converts the date to julian day and adds the fractional
# day represented by the hours and minutes
julianDayTime = function(date, hour_min) {
require(lubridate)
jday = yday(date)
temp = sapply(strsplit(hour_min, ":"), function(x) {
x = as.numeric(x)
x[1] + x[2]/60
})
output = jday + temp/24
return(output)
}
NCBG_PR_frassdata = frassData(open = T)
filterpaper = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#subset weight & pcs by unique circles, then sum (to account for additional days collected in milkjug)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = filterpaper, sum)
view(filterpaper)
filterpaper
View(filterpaper)
filterpaper[ ! filterpaper$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
srtd_filterpaper = filterpaper[ ! filterpaper$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
srtd_filterpaper
warnings()
filterpaper = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
srtd_filterpaper = filterpaper[ ! filterpaper$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
View(srtd_filterpaper)
filtermass
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create new data table with the filter paper traps that are next to milk jug traps
filterpaper = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
srtd_filterpaper = filterpaper[ ! filterpaper$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#subset weight & pcs by unique circles, then sum (to account for additional days collected in milkjug)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
View(filtermass)
filterpaper = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
srtd_filterpaper = filterpaper[ ! filterpaper$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#subset weight & pcs by unique circles, then sum (to account for additional days collected in milkjug)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
filterpaper = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
srtd_filterpaper = filterpaper[ ! filterpaper$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#plot comparing sorted pcs
milkjug_filter_frasstraps = merge(filterpcs, filtermass, by = "Survey")
View(milkjug_filter_frasstraps)
View(filtermass)
view(filterpcs)
View(filterpcs)
milkjugs = data[c(74:89),]
View(milkjugs)
# Script for analyzing milk jug frass data
frassLoad = function(open = T, write = F) {
require(gsheet)
url = "https://docs.google.com/spreadsheets/d/1RwXzwhHUbP0m5gKSOVhnKZbS1C_NrbdfHLglIVCzyFc/edit#gid=806965256"
data = gsheet2tbl(url)
if (write) {
# Write a copy
write.csv(data, paste('data/frass_', Sys.Date(), '.csv', sep = ''),
row.names = F)
}
if (open) { return (data) }
}
# Script for analyzing filter paper data
library(gsheet)
library(dplyr)
library(tidyr)
# Function for reading in frass data from GoogleDoc
# *if aim is to backup GoogleDoc and write to disk only, then open =F and write = T
# *if aim is to use data without writing to disk, then open = T and write = F
frassData = function(open = F, write = F) {
require(gsheet)
url = "https://docs.google.com/spreadsheets/d/1RwXzwhHUbP0m5gKSOVhnKZbS1C_NrbdfHLglIVCzyFc/edit#gid=1479231778"
data = gsheet2tbl(url)
if (write) {
# Write a copy
write.csv(data, paste('data/frass_', Sys.Date(), '.csv', sep = ''),
row.names = F)
}
if (open) { return (data) }
}
# Function that takes a date field (formatted as %m/%d/%Y) and a time field
# (hh:mm in 24h time), converts the date to julian day and adds the fractional
# day represented by the hours and minutes
julianDayTime = function(date, hour_min) {
require(lubridate)
jday = yday(date)
temp = sapply(strsplit(hour_min, ":"), function(x) {
x = as.numeric(x)
x[1] + x[2]/60
})
output = jday + temp/24
return(output)
}
#renaming data sets
data = frassLoad(open = T)
NCBG_PR_frassdata = frassData(open = T)
milkjugs = data[c(74:89)]
milkjugs = data[c(74:89),]
View(milkjugs)
View(frass_filter)
frass_filter = merge(filterpcs, filtermass, by = "Survey")
View(frass_filter)
milkjugs = data[c(74:89),c("Pieces_Raw", "Pieces_Sorted")]
View(milkjugs)
milkjugs = data[c(74:89),c("Survey","Pieces_Raw", "Pieces_Sorted")]
milkjugs = data[c(74:89),c("Survey","Pieces_Raw", "Pieces_Sorted")]
milkjugs = data[c(74:89),c("Survey","Pieces_Raw", "Pieces_Sorted")]
milkjugs = data[c(74:89),c("Survey","Pieces_Raw", "Pieces_Sorted")]
milkjugs = data[c(74:89),c("Survey","Pieces_Raw", "Pieces_Sorted")]
# Script for analyzing milk jug frass data
frassLoad = function(open = T, write = F) {
require(gsheet)
url = "https://docs.google.com/spreadsheets/d/1RwXzwhHUbP0m5gKSOVhnKZbS1C_NrbdfHLglIVCzyFc/edit#gid=806965256"
data = gsheet2tbl(url)
if (write) {
# Write a copy
write.csv(data, paste('data/frass_', Sys.Date(), '.csv', sep = ''),
row.names = F)
}
if (open) { return (data) }
}
# Script for analyzing filter paper data
library(gsheet)
library(dplyr)
library(tidyr)
# Function for reading in frass data from GoogleDoc
# *if aim is to backup GoogleDoc and write to disk only, then open =F and write = T
# *if aim is to use data without writing to disk, then open = T and write = F
frassData = function(open = F, write = F) {
require(gsheet)
url = "https://docs.google.com/spreadsheets/d/1RwXzwhHUbP0m5gKSOVhnKZbS1C_NrbdfHLglIVCzyFc/edit#gid=1479231778"
data = gsheet2tbl(url)
if (write) {
# Write a copy
write.csv(data, paste('data/frass_', Sys.Date(), '.csv', sep = ''),
row.names = F)
}
if (open) { return (data) }
}
# Function that takes a date field (formatted as %m/%d/%Y) and a time field
# (hh:mm in 24h time), converts the date to julian day and adds the fractional
# day represented by the hours and minutes
julianDayTime = function(date, hour_min) {
require(lubridate)
jday = yday(date)
temp = sapply(strsplit(hour_min, ":"), function(x) {
x = as.numeric(x)
x[1] + x[2]/60
})
output = jday + temp/24
return(output)
}
#renaming data sets
data = frassLoad(open = T)
NCBG_PR_frassdata = frassData(open = T)
#create new data table for milk jug isolating by frass trap site
milkjugs = data[c(74:89),c("Survey","Pieces_Raw", "Pieces_Sorted")]
View(milkjugs)
milkjugs = data[c(73:88),c("Survey","Pieces_Raw", "Pieces_Sorted")]
View(milkjugs)
milkjugs = data[c(73:88),c("Survey","Weight_Sorted", "Pieces_Sorted")]
View(milkjugs)
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for filter paper traps with pieces and mass merged
filterpaper = merge(filterpcs, filtermass, by = "Survey")
View(filterpaper)
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197,1210:1225),]
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for filter paper traps with pieces and mass merged
filterpaper = merge(filterpcs, filtermass, by = "Survey")
View(filterpaper)
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = "Survey")
#create data set with normal values and collection dates
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225),]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
filterpaper = merge(filter_sum, filter_normal)
#create new data table for filter paper from 7/6
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = "Survey")
#create data set with normal values and collection dates
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225),]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
filterpaper = merge(filter_sum, filter_normal, by = "Survey")
View(filterpaper)
View(filter_normal)
View(filterfrass_all)
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225), c("Survey","Frass.mass..mg","Frass.number")]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225), c("Survey","Frass.mass..mg.","Frass.number")]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
View(filter_normal)
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = "Survey")
#create data set with normal values and collection dates
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225), c("Survey","Frass.mass..mg.","Frass.number")]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#combine adjusted filter paper frass data set with normal data set
filterpaper = rbind(filter_sum, filter_normal)
View(filterpaper)
View(filter_sum)
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = "Survey")
#create data set with normal values and collection dates
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225), c("Survey","Frass.mass..mg.","Frass.number")]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#combine adjusted filter paper frass data set with normal data set
filterpaper = rbind(filter_sum, filter_normal)
#create new data table for milk jug isolating by frass trap site
milkjugs = data[c(73:88),c("Survey","Weight_Sorted", "Pieces_Sorted")]
#merge both data sets to compare milk jug and filter paper mass and peices
compare.frasstraps = merge(milkjugs, filterpaper, by = "Survey")
View(compare.frasstraps)
View(milkjugs)
#create new data table for filter paper from 7/6
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBD","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = "Survey")
#create data set with normal values and collection dates
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225), c("Survey","Frass.mass..mg.","Frass.number")]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#combine adjusted filter paper frass data set with normal data set
filterpaper = rbind(filter_sum, filter_normal)
#create new data table for milk jug isolating by frass trap site
milkjugs = data[c(73:88),c("Survey","Weight_Sorted", "Pieces_Sorted")]
#merge both data sets to compare milk jug and filter paper mass and peices
compare.frasstraps = merge(milkjugs, filterpaper, by = "Survey")
View(compare.frasstraps)
#must sum filter paper frass by circle to make accurate comparison
#create new data table for filter paper from 7/6
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBD","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = "Survey")
#create data set with normal values and collection dates
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225), c("Survey","Date.Set", "Date.Collected","Frass.mass..mg.","Frass.number")]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#combine adjusted filter paper frass data set with normal data set
filterpaper = rbind(filter_sum, filter_normal)
#create new data table for milk jug isolating by frass trap site
milkjugs = data[c(73:88),c("Survey","Date.Set", "Date.Collected", "Weight_Sorted", "Pieces_Sorted")]
#merge both data sets to compare milk jug and filter paper mass and peices
compare.frasstraps = merge(milkjugs, filterpaper, by = "Survey")
filter_sum = merge(filterpcs, filtermass, by = c("Survey", "Date.Set", "Date.Collected")
filter_sum = merge(filterpcs, filtermass, by = c("Survey", "Date.Set", "Date.Collected"))
# Img_raw vs.Img_sort
plot(data$Img_Raw[data$Img_Sorted<20], data$Img_Sorted[data$Img_Sorted<20], main = "Comparison Img_Raw vs. Img_Sorted (% of area estimate)", xlab = "Raw Img.", ylab ="Sorted Img.", col = 'violet', pch = 20)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = "Survey", "Date.Set", "Date.Collected")
View(filterpcs)
View(srtd_filterpaper)
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBD","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
groupcol <- c("Survey","Date.Set", "Date.Collected")
#merge(
#  aggregate(data[,c("Weight", "Reps", "EstMax")], by = data[grpvar], FUN = max),
#  aggregate(data[,c("RepxWeight", "Note")], by = data[grpvar], FUN = function(a) a[1]),
#  by = grpvar
#)
filter_sum = merge(filterpcs, filtermass, by = "groupcol")
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBD","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
groupcol <- c("Survey","Date.Set", "Date.Collected")
#merge(
#  aggregate(data[,c("Weight", "Reps", "EstMax")], by = data[grpvar], FUN = max),
#  aggregate(data[,c("RepxWeight", "Note")], by = data[grpvar], FUN = function(a) a[1]),
#  by = grpvar
#)
filter_sum = merge(filterpcs, filtermass, by = groupcol)
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBD","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
groupcol <- c("Survey","Date.Set", "Date.Collected")
filter_sum = merge(filterpcs, filtermass, by = groupcol)
#create new data table for filter paper from 7/6
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBD","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = Survey)
filterfrass_all = NCBG_PR_frassdata[c(1154:1169,1182:1197),]
#isolate by frass trap site
srtd_filterpaper = filterfrass_all[ ! filterfrass_all$Survey %in% c("1DBD","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#Sum values of same filter paper frass traps (to account for the additional collection days)
filtermass = aggregate(Frass.mass..mg. ~ Survey, data = srtd_filterpaper, sum)
filterpcs = aggregate(Frass.number ~ Survey, data = srtd_filterpaper, sum)
#create data set for summed values of filter paper traps, with pieces and mass merged
filter_sum = merge(filterpcs, filtermass, by = "Survey")
View(filter_sum)
View(filtermass)
View(filterpaper)
filterdates_nonsum = NCBG_PR_frassdata[c(1210:1225), c("Survey","Frass.mass..mg.","Frass.number")]
#isolate by frass trap site
filter_normal = filterdates_nonsum[ ! filterdates_nonsum$Survey %in% c("1DBN","2DBS", "3DBV","4DCE","5DCI","6DCM","7DCQ","8DCV"), ]
#combine adjusted filter paper frass data set with normal data set
filterpaper = rbind(filter_sum, filter_normal)
View(filterpaper)
#create new data table for milk jug isolating by frass trap site
milkjugs = data[c(73:88),c("Survey","Weight_Sorted", "Pieces_Sorted")]
compare.frasstraps = merge(milkjugs, filterpaper, by = "Survey")
View(compare.frasstraps)
